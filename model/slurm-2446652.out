[2025-04-28 18:47:21,166] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-04-28 18:47:26,899] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/ms1438/.conda/envs/venv/lib/python3.12/site-packages/accelerate/accelerator.py:249: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of ðŸ¤— Accelerate. Use `project_dir` instead.
  warnings.warn(
/home/ms1438/.conda/envs/venv/lib/python3.12/site-packages/accelerate/accelerator.py:416: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
04/28/2025 18:47:29 - INFO - __main__ - Distributed environment: DistributedType.NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: fp16

You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
/home/ms1438/.conda/envs/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/home/ms1438/.conda/envs/venv/lib/python3.12/site-packages/accelerate/accelerator.py:1235: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  model.forward = torch.cuda.amp.autocast(dtype=torch.float16)(model.forward)
04/28/2025 18:47:30 - INFO - __main__ - ***** Running training *****
04/28/2025 18:47:30 - INFO - __main__ -   Num examples = 1683
04/28/2025 18:47:30 - INFO - __main__ -   Num Epochs = 140
04/28/2025 18:47:30 - INFO - __main__ -   Instantaneous batch size per device = 8
04/28/2025 18:47:30 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 32
04/28/2025 18:47:30 - INFO - __main__ -   Gradient Accumulation steps = 4
04/28/2025 18:47:30 - INFO - __main__ -   Total optimization steps = 7420
CUDA_VISIBLE_DEVICES: 0
CUDA device count: 1
CUDA current device: 0
CUDA device name: Tesla V100-PCIE-32GB
Length of dataset:  1683
Total number of trainable parameters: 114223628
num_update_steps_per_epoch 53
max_train_steps None
max_train_steps 7420
  0%|          | 0/7420 [00:00<?, ?it/s]  0%|          | 0/7420 [00:11<?, ?it/s, Loss=6.87]  0%|          | 1/7420 [00:11<22:54:41, 11.12s/it, Loss=6.87]  0%|          | 1/7420 [00:15<22:54:41, 11.12s/it, Loss=6.75]  0%|          | 2/7420 [00:15<14:30:50,  7.04s/it, Loss=6.75]  0%|          | 2/7420 [00:19<14:30:50,  7.04s/it, Loss=6.77]  0%|          | 3/7420 [00:19<12:07:31,  5.89s/it, Loss=6.77]  0%|          | 3/7420 [00:23<12:07:31,  5.89s/it, Loss=6.74]  0%|          | 4/7420 [00:23<10:43:42,  5.21s/it, Loss=6.74]  0%|          | 4/7420 [00:28<10:43:42,  5.21s/it, Loss=6.81]  0%|          | 5/7420 [00:28<9:58:53,  4.85s/it, Loss=6.81]   0%|          | 5/7420 [00:32<9:58:53,  4.85s/it, Loss=6.91]  0%|          | 6/7420 [00:32<9:33:23,  4.64s/it, Loss=6.91]  0%|          | 6/7420 [00:36<9:33:23,  4.64s/it, Loss=6.86]  0%|          | 7/7420 [00:36<9:12:35,  4.47s/it, Loss=6.86]  0%|          | 7/7420 [00:40<9:12:35,  4.47s/it, Loss=6.71]  0%|          | 8/7420 [00:40<9:03:25,  4.40s/it, Loss=6.71]  0%|          | 8/7420 [00:45<9:03:25,  4.40s/it, Loss=6.88]  0%|          | 9/7420 [00:45<9:00:20,  4.37s/it, Loss=6.88]  0%|          | 9/7420 [00:49<9:00:20,  4.37s/it, Loss=6.87]  0%|          | 10/7420 [00:49<9:00:56,  4.38s/it, Loss=6.87]  0%|          | 10/7420 [00:53<9:00:56,  4.38s/it, Loss=6.84]  0%|          | 11/7420 [00:53<8:55:44,  4.34s/it, Loss=6.84]  0%|          | 11/7420 [00:58<8:55:44,  4.34s/it, Loss=6.79]  0%|          | 12/7420 [00:58<8:54:38,  4.33s/it, Loss=6.79]  0%|          | 12/7420 [01:02<8:54:38,  4.33s/it, Loss=6.83]  0%|          | 13/7420 [01:02<9:13:53,  4.49s/it, Loss=6.83]  0%|          | 13/7420 [01:07<9:13:53,  4.49s/it, Loss=6.65]  0%|          | 14/7420 [01:07<9:04:16,  4.41s/it, Loss=6.65]  0%|          | 14/7420 [01:11<9:04:16,  4.41s/it, Loss=6.78]  0%|          | 15/7420 [01:11<9:17:50,  4.52s/it, Loss=6.78]  0%|          | 15/7420 [01:16<9:17:50,  4.52s/it, Loss=6.68]  0%|          | 16/7420 [01:16<9:01:19,  4.39s/it, Loss=6.68]  0%|          | 16/7420 [01:20<9:01:19,  4.39s/it, Loss=6.81]  0%|          | 17/7420 [01:20<9:05:27,  4.42s/it, Loss=6.81]  0%|          | 17/7420 [01:24<9:05:27,  4.42s/it, Loss=6.75]  0%|          | 18/7420 [01:24<8:58:37,  4.37s/it, Loss=6.75]  0%|          | 18/7420 [01:28<8:58:37,  4.37s/it, Loss=6.88]  0%|          | 19/7420 [01:28<8:50:15,  4.30s/it, Loss=6.88]  0%|          | 19/7420 [01:33<8:50:15,  4.30s/it, Loss=6.79]  0%|          | 20/7420 [01:33<8:53:10,  4.32s/it, Loss=6.79]  0%|          | 20/7420 [01:37<8:53:10,  4.32s/it, Loss=6.79]  0%|          | 21/7420 [01:37<8:58:07,  4.36s/it, Loss=6.79]  0%|          | 21/7420 [01:41<8:58:07,  4.36s/it, Loss=6.73]  0%|          | 22/7420 [01:41<8:36:11,  4.19s/it, Loss=6.73]  0%|          | 22/7420 [01:45<8:36:11,  4.19s/it, Loss=6.8]   0%|          | 23/7420 [01:45<8:41:40,  4.23s/it, Loss=6.8]  0%|          | 23/7420 [01:49<8:41:40,  4.23s/it, Loss=6.82]  0%|          | 24/7420 [01:49<8:32:58,  4.16s/it, Loss=6.82]  0%|          | 24/7420 [01:54<8:32:58,  4.16s/it, Loss=6.88]  0%|          | 25/7420 [01:54<8:44:35,  4.26s/it, Loss=6.88]  0%|          | 25/7420 [01:58<8:44:35,  4.26s/it, Loss=6.83]  0%|          | 26/7420 [01:58<8:42:24,  4.24s/it, Loss=6.83]  0%|          | 26/7420 [02:02<8:42:24,  4.24s/it, Loss=6.68]  0%|          | 27/7420 [02:02<8:48:04,  4.29s/it, Loss=6.68]  0%|          | 27/7420 [02:07<8:48:04,  4.29s/it, Loss=6.75]  0%|          | 28/7420 [02:07<9:09:23,  4.46s/it, Loss=6.75]  0%|          | 28/7420 [02:12<9:09:23,  4.46s/it, Loss=6.58]  0%|          | 29/7420 [02:12<9:05:54,  4.43s/it, Loss=6.58]  0%|          | 29/7420 [02:16<9:05:54,  4.43s/it, Loss=6.72]  0%|          | 30/7420 [02:16<8:54:52,  4.34s/it, Loss=6.72]  0%|          | 30/7420 [02:20<8:54:52,  4.34s/it, Loss=6.75]  0%|          | 31/7420 [02:20<9:01:03,  4.39s/it, Loss=6.75]  0%|          | 31/7420 [02:25<9:01:03,  4.39s/it, Loss=6.85]  0%|          | 32/7420 [02:25<9:11:50,  4.48s/it, Loss=6.85]  0%|          | 32/7420 [02:29<9:11:50,  4.48s/it, Loss=6.8]   0%|          | 33/7420 [02:29<9:11:19,  4.48s/it, Loss=6.8]  0%|          | 33/7420 [02:34<9:11:19,  4.48s/it, Loss=6.49]  0%|          | 34/7420 [02:34<9:07:14,  4.45s/it, Loss=6.49]  0%|          | 34/7420 [02:38<9:07:14,  4.45s/it, Loss=6.67]  0%|          | 35/7420 [02:38<8:59:24,  4.38s/it, Loss=6.67]  0%|          | 35/7420 [02:42<8:59:24,  4.38s/it, Loss=6.82]  0%|          | 36/7420 [02:42<8:57:41,  4.37s/it, Loss=6.82]  0%|          | 36/7420 [02:47<8:57:41,  4.37s/it, Loss=6.65]  0%|          | 37/7420 [02:47<8:49:53,  4.31s/it, Loss=6.65]  0%|          | 37/7420 [02:51<8:49:53,  4.31s/it, Loss=6.64]  1%|          | 38/7420 [02:51<8:50:41,  4.31s/it, Loss=6.64]  1%|          | 38/7420 [02:55<8:50:41,  4.31s/it, Loss=6.69]  1%|          | 39/7420 [02:55<8:44:52,  4.27s/it, Loss=6.69]  1%|          | 39/7420 [02:59<8:44:52,  4.27s/it, Loss=6.79]  1%|          | 40/7420 [02:59<8:40:11,  4.23s/it, Loss=6.79]  1%|          | 40/7420 [03:03<8:40:11,  4.23s/it, Loss=6.74]  1%|          | 41/7420 [03:03<8:37:53,  4.21s/it, Loss=6.74]  1%|          | 41/7420 [03:08<8:37:53,  4.21s/it, Loss=6.8]   1%|          | 42/7420 [03:08<8:44:27,  4.26s/it, Loss=6.8]  1%|          | 42/7420 [03:12<8:44:27,  4.26s/it, Loss=6.7]  1%|          | 43/7420 [03:12<8:51:25,  4.32s/it, Loss=6.7]  1%|          | 43/7420 [03:16<8:51:25,  4.32s/it, Loss=6.76]  1%|          | 44/7420 [03:16<8:46:26,  4.28s/it, Loss=6.76]  1%|          | 44/7420 [03:21<8:46:26,  4.28s/it, Loss=6.81]  1%|          | 45/7420 [03:21<8:49:40,  4.31s/it, Loss=6.81]  1%|          | 45/7420 [03:25<8:49:40,  4.31s/it, Loss=6.87]  1%|          | 46/7420 [03:25<8:50:45,  4.32s/it, Loss=6.87]  1%|          | 46/7420 [03:29<8:50:45,  4.32s/it, Loss=6.53]  1%|          | 47/7420 [03:29<8:44:16,  4.27s/it, Loss=6.53]  1%|          | 47/7420 [03:34<8:44:16,  4.27s/it, Loss=6.64]  1%|          | 48/7420 [03:34<8:45:03,  4.27s/it, Loss=6.64]  1%|          | 48/7420 [03:38<8:45:03,  4.27s/it, Loss=6.5]   1%|          | 49/7420 [03:38<8:54:24,  4.35s/it, Loss=6.5]  1%|          | 49/7420 [03:42<8:54:24,  4.35s/it, Loss=6.63]  1%|          | 50/7420 [03:42<8:42:19,  4.25s/it, Loss=6.63]  1%|          | 50/7420 [03:45<8:42:19,  4.25s/it, Loss=6.67]  1%|          | 51/7420 [03:45<8:10:44,  4.00s/it, Loss=6.67]  1%|          | 51/7420 [03:49<8:10:44,  4.00s/it, Loss=6.63]  1%|          | 52/7420 [03:49<7:43:10,  3.77s/it, Loss=6.63]  1%|          | 52/7420 [03:50<7:43:10,  3.77s/it, Loss=6.61]  1%|          | 53/7420 [03:50<6:28:00,  3.16s/it, Loss=6.61]04/28/2025 18:51:21 - INFO - __main__ - {'epoch': 69, 'step': 53, 'train_loss': 6.7535}
04/28/2025 18:51:21 - INFO - accelerate.accelerator - Saving current state to /scratch/network/ms1438/output_test_new/epoch_69
04/28/2025 18:51:23 - INFO - accelerate.checkpointing - Model weights saved in /scratch/network/ms1438/output_test_new/epoch_69/pytorch_model.bin
04/28/2025 18:51:24 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch/network/ms1438/output_test_new/epoch_69/optimizer.bin
04/28/2025 18:51:24 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch/network/ms1438/output_test_new/epoch_69/scheduler.bin
04/28/2025 18:51:24 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch/network/ms1438/output_test_new/epoch_69/scaler.pt
04/28/2025 18:51:24 - INFO - accelerate.checkpointing - Random states saved in /scratch/network/ms1438/output_test_new/epoch_69/random_states_0.pkl
Epoch: 68, Loss Train: 6.7535

  1%|          | 53/7420 [04:04<6:28:00,  3.16s/it, Loss=6.55]  1%|          | 54/7420 [04:04<13:03:19,  6.38s/it, Loss=6.55]  1%|          | 54/7420 [04:09<13:03:19,  6.38s/it, Loss=6.46]  1%|          | 55/7420 [04:09<12:14:12,  5.98s/it, Loss=6.46]  1%|          | 55/7420 [04:13<12:14:12,  5.98s/it, Loss=6.71]  1%|          | 56/7420 [04:13<11:01:38,  5.39s/it, Loss=6.71]  1%|          | 56/7420 [04:18<11:01:38,  5.39s/it, Loss=6.67]  1%|          | 57/7420 [04:18<10:29:59,  5.13s/it, Loss=6.67]  1%|          | 57/7420 [04:22<10:29:59,  5.13s/it, Loss=6.7]   1%|          | 58/7420 [04:22<9:56:55,  4.86s/it, Loss=6.7]   1%|          | 58/7420 [04:27<9:56:55,  4.86s/it, Loss=6.49]  1%|          | 59/7420 [04:27<9:45:18,  4.77s/it, Loss=6.49]  1%|          | 59/7420 [04:31<9:45:18,  4.77s/it, Loss=6.8]   1%|          | 60/7420 [04:31<9:21:34,  4.58s/it, Loss=6.8]  1%|          | 60/7420 [04:35<9:21:34,  4.58s/it, Loss=6.55]  1%|          | 61/7420 [04:35<9:15:58,  4.53s/it, Loss=6.55]  1%|          | 61/7420 [04:40<9:15:58,  4.53s/it, Loss=6.51]  1%|          | 62/7420 [04:40<9:04:48,  4.44s/it, Loss=6.51]  1%|          | 62/7420 [04:44<9:04:48,  4.44s/it, Loss=6.53]  1%|          | 63/7420 [04:44<9:01:26,  4.42s/it, Loss=6.53]  1%|          | 63/7420 [04:49<9:01:26,  4.42s/it, Loss=6.67]  1%|          | 64/7420 [04:49<9:13:13,  4.51s/it, Loss=6.67]  1%|          | 64/7420 [04:53<9:13:13,  4.51s/it, Loss=6.71]  1%|          | 65/7420 [04:53<8:55:25,  4.37s/it, Loss=6.71]  1%|          | 65/7420 [04:57<8:55:25,  4.37s/it, Loss=6.68]  1%|          | 66/7420 [04:57<8:47:41,  4.31s/it, Loss=6.68]  1%|          | 66/7420 [05:01<8:47:41,  4.31s/it, Loss=6.22]  1%|          | 67/7420 [05:01<8:53:20,  4.35s/it, Loss=6.22]  1%|          | 67/7420 [05:06<8:53:20,  4.35s/it, Loss=6.28]  1%|          | 68/7420 [05:06<9:01:40,  4.42s/it, Loss=6.28]  1%|          | 68/7420 [05:10<9:01:40,  4.42s/it, Loss=6.4]   1%|          | 69/7420 [05:10<9:03:00,  4.43s/it, Loss=6.4]  1%|          | 69/7420 [05:15<9:03:00,  4.43s/it, Loss=6.62]  1%|          | 70/7420 [05:15<9:08:00,  4.47s/it, Loss=6.62]  1%|          | 70/7420 [05:19<9:08:00,  4.47s/it, Loss=6.66]  1%|          | 71/7420 [05:19<9:05:58,  4.46s/it, Loss=6.66]  1%|          | 71/7420 [05:24<9:05:58,  4.46s/it, Loss=6.72]  1%|          | 72/7420 [05:24<9:04:13,  4.44s/it, Loss=6.72]  1%|          | 72/7420 [05:28<9:04:13,  4.44s/it, Loss=6.38]  1%|          | 73/7420 [05:28<9:04:51,  4.45s/it, Loss=6.38]  1%|          | 73/7420 [05:33<9:04:51,  4.45s/it, Loss=6.65]  1%|          | 74/7420 [05:33<9:09:43,  4.49s/it, Loss=6.65]  1%|          | 74/7420 [05:37<9:09:43,  4.49s/it, Loss=6.45]  1%|          | 75/7420 [05:37<9:02:58,  4.44s/it, Loss=6.45]  1%|          | 75/7420 [05:42<9:02:58,  4.44s/it, Loss=6.57]  1%|          | 76/7420 [05:42<9:14:59,  4.53s/it, Loss=6.57]  1%|          | 76/7420 [05:47<9:14:59,  4.53s/it, Loss=6.53]  1%|          | 77/7420 [05:47<9:31:14,  4.67s/it, Loss=6.53]  1%|          | 77/7420 [05:51<9:31:14,  4.67s/it, Loss=6.55]  1%|          | 78/7420 [05:51<9:21:09,  4.59s/it, Loss=6.55]  1%|          | 78/7420 [05:56<9:21:09,  4.59s/it, Loss=6.47]  1%|          | 79/7420 [05:56<9:15:05,  4.54s/it, Loss=6.47]  1%|          | 79/7420 [06:00<9:15:05,  4.54s/it, Loss=6.52]  1%|          | 80/7420 [06:00<8:59:34,  4.41s/it, Loss=6.52]  1%|          | 80/7420 [06:04<8:59:34,  4.41s/it, Loss=6.54]  1%|          | 81/7420 [06:04<9:02:27,  4.43s/it, Loss=6.54]  1%|          | 81/7420 [06:09<9:02:27,  4.43s/it, Loss=6.23]  1%|          | 82/7420 [06:09<8:58:48,  4.41s/it, Loss=6.23]  1%|          | 82/7420 [06:13<8:58:48,  4.41s/it, Loss=6.55]  1%|          | 83/7420 [06:13<9:03:26,  4.44s/it, Loss=6.55]  1%|          | 83/7420 [06:17<9:03:26,  4.44s/it, Loss=6.25]  1%|          | 84/7420 [06:17<8:47:49,  4.32s/it, Loss=6.25]  1%|          | 84/7420 [06:22<8:47:49,  4.32s/it, Loss=6.5]   1%|          | 85/7420 [06:22<8:53:27,  4.36s/it, Loss=6.5]  1%|          | 85/7420 [06:26<8:53:27,  4.36s/it, Loss=6.31]  1%|          | 86/7420 [06:26<8:56:54,  4.39s/it, Loss=6.31]  1%|          | 86/7420 [06:30<8:56:54,  4.39s/it, Loss=6.31]  1%|          | 87/7420 [06:30<8:52:28,  4.36s/it, Loss=6.31]  1%|          | 87/7420 [06:35<8:52:28,  4.36s/it, Loss=6.61]  1%|          | 88/7420 [06:35<9:03:40,  4.45s/it, Loss=6.61]  1%|          | 88/7420 [06:40<9:03:40,  4.45s/it, Loss=6.31]  1%|          | 89/7420 [06:40<9:13:24,  4.53s/it, Loss=6.31]  1%|          | 89/7420 [06:44<9:13:24,  4.53s/it, Loss=6.53]  1%|          | 90/7420 [06:44<9:01:05,  4.43s/it, Loss=6.53]  1%|          | 90/7420 [06:48<9:01:05,  4.43s/it, Loss=6.22]  1%|          | 91/7420 [06:48<8:54:47,  4.38s/it, Loss=6.22]  1%|          | 91/7420 [06:53<8:54:47,  4.38s/it, Loss=6.53]  1%|          | 92/7420 [06:53<8:56:12,  4.39s/it, Loss=6.53]  1%|          | 92/7420 [06:58<8:56:12,  4.39s/it, Loss=6.35]  1%|â–         | 93/7420 [06:58<9:16:29,  4.56s/it, Loss=6.35]  1%|â–         | 93/7420 [07:02<9:16:29,  4.56s/it, Loss=6.24]  1%|â–         | 94/7420 [07:02<9:06:24,  4.48s/it, Loss=6.24]  1%|â–         | 94/7420 [07:06<9:06:24,  4.48s/it, Loss=6.46]  1%|â–         | 95/7420 [07:06<8:50:43,  4.35s/it, Loss=6.46]  1%|â–         | 95/7420 [07:10<8:50:43,  4.35s/it, Loss=6.15]  1%|â–         | 96/7420 [07:10<8:59:47,  4.42s/it, Loss=6.15]  1%|â–         | 96/7420 [07:15<8:59:47,  4.42s/it, Loss=6.3]   1%|â–         | 97/7420 [07:15<9:11:46,  4.52s/it, Loss=6.3]  1%|â–         | 97/7420 [07:20<9:11:46,  4.52s/it, Loss=6.44]  1%|â–         | 98/7420 [07:20<9:07:24,  4.49s/it, Loss=6.44]  1%|â–         | 98/7420 [07:24<9:07:24,  4.49s/it, Loss=6.3]   1%|â–         | 99/7420 [07:24<8:58:56,  4.42s/it, Loss=6.3]  1%|â–         | 99/7420 [07:28<8:58:56,  4.42s/it, Loss=6.14]  1%|â–         | 100/7420 [07:28<9:00:26,  4.43s/it, Loss=6.14]  1%|â–         | 100/7420 [07:33<9:00:26,  4.43s/it, Loss=6.29]  1%|â–         | 101/7420 [07:33<8:54:41,  4.38s/it, Loss=6.29]  1%|â–         | 101/7420 [07:37<8:54:41,  4.38s/it, Loss=6.08]  1%|â–         | 102/7420 [07:37<9:02:30,  4.45s/it, Loss=6.08]  1%|â–         | 102/7420 [07:41<9:02:30,  4.45s/it, Loss=6.49]  1%|â–         | 103/7420 [07:41<8:49:19,  4.34s/it, Loss=6.49]  1%|â–         | 103/7420 [07:45<8:49:19,  4.34s/it, Loss=6.01]  1%|â–         | 104/7420 [07:45<8:20:53,  4.11s/it, Loss=6.01]  1%|â–         | 104/7420 [07:48<8:20:53,  4.11s/it, Loss=6.39]  1%|â–         | 105/7420 [07:48<7:49:30,  3.85s/it, Loss=6.39]  1%|â–         | 105/7420 [07:50<7:49:30,  3.85s/it, Loss=6.4]   1%|â–         | 106/7420 [07:50<6:32:15,  3.22s/it, Loss=6.4]04/28/2025 18:55:21 - INFO - __main__ - {'epoch': 70, 'step': 106, 'train_loss': 6.4479}
04/28/2025 18:55:21 - INFO - accelerate.accelerator - Saving current state to /scratch/network/ms1438/output_test_new/epoch_70
04/28/2025 18:55:22 - INFO - accelerate.checkpointing - Model weights saved in /scratch/network/ms1438/output_test_new/epoch_70/pytorch_model.bin
04/28/2025 18:55:23 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch/network/ms1438/output_test_new/epoch_70/optimizer.bin
04/28/2025 18:55:23 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch/network/ms1438/output_test_new/epoch_70/scheduler.bin
04/28/2025 18:55:23 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch/network/ms1438/output_test_new/epoch_70/scaler.pt
04/28/2025 18:55:23 - INFO - accelerate.checkpointing - Random states saved in /scratch/network/ms1438/output_test_new/epoch_70/random_states_0.pkl
Epoch: 69, Loss Train: 6.4479

  1%|â–         | 106/7420 [08:04<6:32:15,  3.22s/it, Loss=6.39]  1%|â–         | 107/7420 [08:04<13:21:45,  6.58s/it, Loss=6.39]  1%|â–         | 107/7420 [08:09<13:21:45,  6.58s/it, Loss=6.31]  1%|â–         | 108/7420 [08:09<12:09:04,  5.98s/it, Loss=6.31]  1%|â–         | 108/7420 [08:13<12:09:04,  5.98s/it, Loss=6.34]  1%|â–         | 109/7420 [08:13<11:11:54,  5.51s/it, Loss=6.34]  1%|â–         | 109/7420 [08:18<11:11:54,  5.51s/it, Loss=6.41]  1%|â–         | 110/7420 [08:18<10:43:29,  5.28s/it, Loss=6.41]  1%|â–         | 110/7420 [08:23<10:43:29,  5.28s/it, Loss=6.34]  1%|â–         | 111/7420 [08:23<10:23:00,  5.11s/it, Loss=6.34]  1%|â–         | 111/7420 [08:27<10:23:00,  5.11s/it, Loss=6.1]   2%|â–         | 112/7420 [08:27<9:47:08,  4.82s/it, Loss=6.1]   2%|â–         | 112/7420 [08:31<9:47:08,  4.82s/it, Loss=6.14]  2%|â–         | 113/7420 [08:31<9:29:05,  4.67s/it, Loss=6.14]  2%|â–         | 113/7420 [08:36<9:29:05,  4.67s/it, Loss=5.76]  2%|â–         | 114/7420 [08:36<9:26:23,  4.65s/it, Loss=5.76]  2%|â–         | 114/7420 [08:40<9:26:23,  4.65s/it, Loss=6.36]  2%|â–         | 115/7420 [08:40<9:23:31,  4.63s/it, Loss=6.36]  2%|â–         | 115/7420 [08:45<9:23:31,  4.63s/it, Loss=5.97]  2%|â–         | 116/7420 [08:45<9:16:57,  4.58s/it, Loss=5.97]  2%|â–         | 116/7420 [08:49<9:16:57,  4.58s/it, Loss=5.91]  2%|â–         | 117/7420 [08:49<9:05:09,  4.48s/it, Loss=5.91]  2%|â–         | 117/7420 [08:54<9:05:09,  4.48s/it, Loss=6.44]  2%|â–         | 118/7420 [08:54<9:10:08,  4.52s/it, Loss=6.44]  2%|â–         | 118/7420 [08:58<9:10:08,  4.52s/it, Loss=6.09]  2%|â–         | 119/7420 [08:58<9:11:00,  4.53s/it, Loss=6.09]  2%|â–         | 119/7420 [09:02<9:11:00,  4.53s/it, Loss=6.28]  2%|â–         | 120/7420 [09:02<8:52:41,  4.38s/it, Loss=6.28]  2%|â–         | 120/7420 [09:07<8:52:41,  4.38s/it, Loss=6.33]  2%|â–         | 121/7420 [09:07<9:04:50,  4.48s/it, Loss=6.33]  2%|â–         | 121/7420 [09:12<9:04:50,  4.48s/it, Loss=5.96]  2%|â–         | 122/7420 [09:12<9:08:56,  4.51s/it, Loss=5.96]  2%|â–         | 122/7420 [09:16<9:08:56,  4.51s/it, Loss=6.04]  2%|â–         | 123/7420 [09:16<8:58:20,  4.43s/it, Loss=6.04]  2%|â–         | 123/7420 [09:20<8:58:20,  4.43s/it, Loss=6.23]  2%|â–         | 124/7420 [09:20<9:01:31,  4.45s/it, Loss=6.23]  2%|â–         | 124/7420 [09:25<9:01:31,  4.45s/it, Loss=5.98]  2%|â–         | 125/7420 [09:25<9:07:51,  4.51s/it, Loss=5.98]  2%|â–         | 125/7420 [09:29<9:07:51,  4.51s/it, Loss=5.86]  2%|â–         | 126/7420 [09:29<9:03:14,  4.47s/it, Loss=5.86]  2%|â–         | 126/7420 [09:34<9:03:14,  4.47s/it, Loss=5.58]  2%|â–         | 127/7420 [09:34<9:09:06,  4.52s/it, Loss=5.58]  2%|â–         | 127/7420 [09:38<9:09:06,  4.52s/it, Loss=6.27]  2%|â–         | 128/7420 [09:38<9:05:32,  4.49s/it, Loss=6.27]  2%|â–         | 128/7420 [09:43<9:05:32,  4.49s/it, Loss=6.1]   2%|â–         | 129/7420 [09:43<9:03:03,  4.47s/it, Loss=6.1]  2%|â–         | 129/7420 [09:47<9:03:03,  4.47s/it, Loss=6.25]  2%|â–         | 130/7420 [09:47<8:54:12,  4.40s/it, Loss=6.25]  2%|â–         | 130/7420 [09:52<8:54:12,  4.40s/it, Loss=5.89]  2%|â–         | 131/7420 [09:52<9:06:05,  4.50s/it, Loss=5.89]  2%|â–         | 131/7420 [09:56<9:06:05,  4.50s/it, Loss=5.82]  2%|â–         | 132/7420 [09:56<9:11:14,  4.54s/it, Loss=5.82]  2%|â–         | 132/7420 [10:01<9:11:14,  4.54s/it, Loss=6.09]  2%|â–         | 133/7420 [10:01<9:04:40,  4.48s/it, Loss=6.09]  2%|â–         | 133/7420 [10:05<9:04:40,  4.48s/it, Loss=5.6]   2%|â–         | 134/7420 [10:05<8:57:39,  4.43s/it, Loss=5.6]  2%|â–         | 134/7420 [10:10<8:57:39,  4.43s/it, Loss=5.79]  2%|â–         | 135/7420 [10:10<9:07:56,  4.51s/it, Loss=5.79]  2%|â–         | 135/7420 [10:14<9:07:56,  4.51s/it, Loss=5.84]  2%|â–         | 136/7420 [10:14<9:10:54,  4.54s/it, Loss=5.84]  2%|â–         | 136/7420 [10:19<9:10:54,  4.54s/it, Loss=6.17]  2%|â–         | 137/7420 [10:19<9:24:06,  4.65s/it, Loss=6.17]  2%|â–         | 137/7420 [10:24<9:24:06,  4.65s/it, Loss=5.46]  2%|â–         | 138/7420 [10:24<9:16:50,  4.59s/it, Loss=5.46]  2%|â–         | 138/7420 [10:28<9:16:50,  4.59s/it, Loss=6.15]  2%|â–         | 139/7420 [10:28<9:12:40,  4.55s/it, Loss=6.15]  2%|â–         | 139/7420 [10:33<9:12:40,  4.55s/it, Loss=5.77]  2%|â–         | 140/7420 [10:33<9:09:55,  4.53s/it, Loss=5.77]  2%|â–         | 140/7420 [10:37<9:09:55,  4.53s/it, Loss=5.88]  2%|â–         | 141/7420 [10:37<8:57:47,  4.43s/it, Loss=5.88]  2%|â–         | 141/7420 [10:41<8:57:47,  4.43s/it, Loss=6.12]  2%|â–         | 142/7420 [10:41<8:52:34,  4.39s/it, Loss=6.12]  2%|â–         | 142/7420 [10:46<8:52:34,  4.39s/it, Loss=6.23]  2%|â–         | 143/7420 [10:46<8:57:03,  4.43s/it, Loss=6.23]  2%|â–         | 143/7420 [10:50<8:57:03,  4.43s/it, Loss=5.91]  2%|â–         | 144/7420 [10:50<8:59:56,  4.45s/it, Loss=5.91]  2%|â–         | 144/7420 [10:55<8:59:56,  4.45s/it, Loss=6.16]  2%|â–         | 145/7420 [10:55<9:01:04,  4.46s/it, Loss=6.16]  2%|â–         | 145/7420 [10:59<9:01:04,  4.46s/it, Loss=5.22]  2%|â–         | 146/7420 [10:59<9:04:18,  4.49s/it, Loss=5.22]  2%|â–         | 146/7420 [11:04<9:04:18,  4.49s/it, Loss=5.72]  2%|â–         | 147/7420 [11:04<9:06:52,  4.51s/it, Loss=5.72]  2%|â–         | 147/7420 [11:09<9:06:52,  4.51s/it, Loss=5.93]  2%|â–         | 148/7420 [11:09<9:14:40,  4.58s/it, Loss=5.93]  2%|â–         | 148/7420 [11:13<9:14:40,  4.58s/it, Loss=6.07]  2%|â–         | 149/7420 [11:13<9:05:42,  4.50s/it, Loss=6.07]  2%|â–         | 149/7420 [11:17<9:05:42,  4.50s/it, Loss=5.58]  2%|â–         | 150/7420 [11:17<9:05:29,  4.50s/it, Loss=5.58]  2%|â–         | 150/7420 [11:22<9:05:29,  4.50s/it, Loss=5.25]  2%|â–         | 151/7420 [11:22<9:11:39,  4.55s/it, Loss=5.25]  2%|â–         | 151/7420 [11:26<9:11:39,  4.55s/it, Loss=5.93]  2%|â–         | 152/7420 [11:26<8:53:36,  4.41s/it, Loss=5.93]  2%|â–         | 152/7420 [11:31<8:53:36,  4.41s/it, Loss=5.5]   2%|â–         | 153/7420 [11:31<8:54:53,  4.42s/it, Loss=5.5]  2%|â–         | 153/7420 [11:35<8:54:53,  4.42s/it, Loss=5.56]  2%|â–         | 154/7420 [11:35<9:02:20,  4.48s/it, Loss=5.56]  2%|â–         | 154/7420 [11:40<9:02:20,  4.48s/it, Loss=5.61]  2%|â–         | 155/7420 [11:40<8:58:46,  4.45s/it, Loss=5.61]  2%|â–         | 155/7420 [11:44<8:58:46,  4.45s/it, Loss=6.13]  2%|â–         | 156/7420 [11:44<8:58:06,  4.44s/it, Loss=6.13]slurmstepd: error: *** JOB 2446652 ON adroit-h11g3 CANCELLED AT 2025-04-28T18:59:18 ***
